ğŸ“š RAG System with FAISS + Sentence Transformers + Groq LLM

A Retrieval-Augmented Generation (RAG) system that loads documents from multiple formats, creates vector embeddings using Sentence Transformers, stores them in FAISS, and generates answers using Groq LLM.

ğŸš€ Features

ğŸ“‚ Load documents from PDF, TXT, CSV, Excel, Word, JSON

âœ‚ï¸ Smart text chunking using LangChain splitters

ğŸ”¢ Embeddings via all-MiniLM-L6-v2

âš¡ Fast vector search with FAISS

ğŸ§  Answer generation using Groq LLM

ğŸ” Persistent vector store (build once, reuse later)

ğŸ›¡ï¸ Safe FAISS loading (no crashes on first run)

ğŸ—ï¸ Project Structure
RAG/
â”‚
â”œâ”€â”€ app.py                     # Entry point
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                       # Input documents
â”‚
â”œâ”€â”€ faiss_store/                # Saved FAISS index
â”‚   â”œâ”€â”€ faiss.index
â”‚   â””â”€â”€ metadata.pkl
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_loader.py          # Load documents
    â”œâ”€â”€ embedding.py            # Chunking & embeddings
    â”œâ”€â”€ vectorstore.py          # FAISS vector store
    â””â”€â”€ search.py               # RAG logic (retrieve + LLM)

ğŸ§° Tech Stack

Python 3.9+

LangChain

Sentence Transformers

FAISS

Groq LLM

dotenv

ğŸ”‘ Environment Setup
1ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate   # Linux / Mac
.venv\Scripts\activate      # Windows

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


Example requirements.txt:

langchain
langchain-community
langchain-groq
sentence-transformers
faiss-cpu
python-dotenv
unstructured
pypdf
docx2txt
openpyxl

3ï¸âƒ£ Set Groq API Key

Create a .env file:

GROQ_API_KEY=your_groq_api_key_here

ğŸ“¥ Add Your Documents

Place your files inside the data/ directory.

Supported formats:

.pdf

.txt

.csv

.xlsx

.docx

.json

â–¶ï¸ Run the Application
python app.py

ğŸ” How It Works
First Run

Loads documents from data/

Splits text into chunks

Generates embeddings

Saves FAISS index to disk

Next Runs

Loads FAISS index directly

Skips re-embedding

Faster startup ğŸš€

ğŸ’¬ Example Query
query = "What is attention mechanism?"

Output:
Summary: Attention mechanism allows a model to focus on relevant parts of input...

ğŸ›¡ï¸ Safe FAISS Loading

The system checks if FAISS files exist before loading:

if not store.load():
    store.build_from_documents(docs)


No crashes on first run âœ…

ğŸ§  Future Improvements

ğŸ” MMR (Max Marginal Relevance) search

ğŸ“š Source citations

ğŸ”„ Hybrid BM25 + FAISS retrieval

ğŸŒ FastAPI backend

ğŸ§µ Streaming LLM responses

ğŸ–¥ï¸ Web UI (Streamlit)

ğŸ“„ License

This project is for learning and experimentation purposes.
You may extend and adapt it freely.

ğŸ™Œ Acknowledgements

FAISS by Meta

Sentence Transformers

LangChain

Groq LLM
